{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9033 - Data Analytics Lab 03: Visual data analysis\n",
    "## Introduction\n",
    "\n",
    "This week's lab provides a practical introduction to visual data analysis. At the end of the lab, you should be able to use pandas to:\n",
    "\n",
    "- Import CSV data with multiple indices.\n",
    "- Make a bar chart.\n",
    "- Make a pie chart.\n",
    "- Make a histogram.\n",
    "- Make a scatter plot matrix.\n",
    "\n",
    "As you will see later, pandas provides a lot of different options for plotting data and we only have time to look at a few in detail. If you're interested, you can find more information on plotting [here](http://pandas.pydata.org/pandas-docs/stable/visualization.html).\n",
    "\n",
    "### The Iris flower data set\n",
    "\n",
    "This week, we'll be using data from the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set), a well-known data set in the world of data analysis. The data set consists of 150 samples taken from three different species of Iris (*Iris setosa*, *Iris virginica* and *Iris versicolor*; 50 samples each). In each case, the length and width (in centimeters) of the Iris' [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal) were measured. The purpose of the lab is to perform some exploratory visual analysis on the data to see what we can learn.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "Let's start by making sure that plots are displayed inline by issuing the *magic command* `%matplotlib inline` and importing pandas in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load the data. Write the path to your iris.csv file in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_csv = \"data/iris.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the CSV file manually (e.g. using spreadsheet software), you will see that it contains six columns: four describe the measurements of the data (i.e. the sepal and petal widths and lengths), while the remaining two describe the species of the data (i.e. *Iris setosa*, *Iris virginica* or *Iris versicolor*) and the index number of the sample, which ranges from 1 to 50 for each species.\n",
    "\n",
    "If we index the measurement data using both the species and sample number information, we can refer to individual measurements per species. Fortunately, with pandas, this is easily done using the same `read_csv` command we used last week. The only difference this time is that we must pass a list of column names (in order) to use as the index.\n",
    "\n",
    "> **Note:** Last week, we passed `index_col='year'`, so that we could index the baby name information in the data frame by year. This week, we'll use the same `index_col` argument, but instead pass a list of strings to use as indices, i.e. `index_col=['index_1', 'index_2', ..., 'index_n']`.\n",
    "\n",
    "Execute the cell below to load the data into a pandas data frame and index that data frame by the `species` and `sample_number` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_csv, index_col=['species', 'sample_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the data we've just loaded. We can start by using the `head` method to take a peak at the first few rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have two index columns on the left side of the data frame: `species` and `sample_number`.\n",
    "\n",
    "## Exploratory data analysis\n",
    "### Summary statistics\n",
    "\n",
    "Let's pick up where we left off in the last lab and compute some summary statistics. We can do this the same way we did last week, using the `describe` method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but what if we want to see data relating to a specific species? This is where our index helps. Because we indexed the data frame using both species and sample numbers, we can reference all the data for a single species by indexing into the data frame using just that species name. For instance, to compute summary statistics for *Iris setosa* alone, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix['setosa'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the summary for *Iris setosa* counts just fifty values, rather than the 150 values in the summary of the entire data frame.\n",
    "\n",
    "What about comparing statistics across different species? Again, with pandas, this is easy. Last week, we saw that pandas has several methods for computing statistics for data frames, e.g. [`mean`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html#pandas.DataFrame.mean), [`median`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.median.html#pandas.DataFrame.median), [`min`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.min.html#pandas.DataFrame.min), [`max`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.max.html#pandas.DataFrame.max) and [`std`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.std.html#pandas.DataFrame.std). Each of these methods accepts an optional `level` argument, which refers to the level of the index you want to compute the function on. For instance, to compute the mean of each sepal and petal length and width for each species, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean(level='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've set `level='species'` because we have two index columns: `species` and `sample_number`. If the `level` argument is not specified, calling `mean` on a data frame has the effect of computing the mean of each column across *all* indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why bother learning methods like `mean`, `median` and `std` when we can just call `describe` to get a complete summary? One reason is because the `describe` method does not accept a `level` argument and so calls to it will compute statistics for *all* of the data in the data frame, unless we index into the data frame first with a specific index reference (like we did earlier when computing a summary for *Iris setosa*).\n",
    "\n",
    "Another reason is that calling these specific instance methods allows us to make further calls to pandas built-in visualisation methods. Let's take a look at some of these in more detail next.\n",
    "\n",
    "### Visual analysis\n",
    "\n",
    "Manually examining tables of numerical values can be an exhausting experience. For instance, when we computed the mean sepal and petal widths and lengths for each species earlier, we ended up with a table of numbers, which doesn't provide much immediate insight into how these quantities vary over species without us having to manually compare the contents of each cell. In cases like this, using a visual technique can be a much better option because it gives us an immediate intuitive sense of what's going on. Let's take a look at a few commonly used techniques next.\n",
    "\n",
    "#### Bar charts\n",
    "\n",
    "Most of pandas plotting functionality is contained in the [`plot`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html#pandas.DataFrame.plot) method of the data frame, which is itself a wrapper for the matplotlib plotting library. To compute a bar chart of some data, all we need to do is call the `plot` method on it with the optional argument `kind='bar'` to specify that we want a bar chart.\n",
    "\n",
    "> **Note:** If `kind` is not specified, then `plot` defaults to a line plot.\n",
    "\n",
    "For instance, to create a bar chart of the mean value of each column in our data frame, all we need to do is call `mean` on the data frame and then call `plot` on the output of our call to `mean` (remembering to set `kind='bar'` too!), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we want to visualise how these quantities vary across species? Easy! All we need to do is pass `level='species'` to the `mean` method, like earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean(level='species').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also produce stacked bar charts, by passing the optional argument `stacked=True`, like in the cell below:\n",
    "\n",
    "> **Note:** By default, if it is not specified, `stacked=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean(level=0).plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make the bar chart horizontal rather than vertical by setting `kind='barh'`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean(level=0).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** pandas provides *lots* of options for plotting. You can find a comprehensive list (with sample code) [here](http://pandas.pydata.org/pandas-docs/stable/visualization.html).\n",
    "\n",
    "We now have a visual representation of the mean values of each sepal and petal measurement across each species. We don't need to worry about creating a chart legend, choosing bar colours or labelling our $x$ axis - pandas (via matplotlib) does this all automatically.\n",
    "\n",
    "##### Legend positioning\n",
    "\n",
    "Sometimes, legends can obscure areas of our visualisations where we want to see detail. For instance, in the last chart above, the legend is blocking the bar representing the average sepal length of *Iris setosa*. We can move the legend to a new location by calling the [`legend`](http://matplotlib.org/1.3.1/api/pyplot_api.html#matplotlib.pyplot.legend) method on the output of the `plot` command, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean(level=0).plot(kind='bar').legend(loc='center left', bbox_to_anchor=(1.0, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `loc` argument specifies a point on the box containing the legend data (in our case, the `center` point of the `left` hand side of the box), while the `bbox_to_anchor` argument specifies the location (in relative (x, y) coordinates) of a point on the boundary box of the chart (i.e. the frame around the chart area) to anchor the selected location to. In this case, we have anchored the `center left` point of the legend box to the point `(1.0, 0.5)` on the boundary box, i.e. the point which is 100% of the way along the $x$ direction of the boundary box and 50% of the way along the $y$ direction of the boundary box.\n",
    "\n",
    "Unfortunately, the syntax here isn't as nice as it could be, but this is the only way to reposition a legend. For those who are interested, a complete list of legend locations (i.e. values for `loc`) is available [here](http://matplotlib.org/1.3.1/api/pyplot_api.html#matplotlib.pyplot.legend).\n",
    "\n",
    "#### Pie charts\n",
    "\n",
    "At the start of this lab, the Iris data set was described as containing 150 samples in total, consisting of 50 from each species. Up until now, we haven't really questioned whether this is true, although as good data analysts we should have! Let's rectify our oversight now.\n",
    "\n",
    "As it turns out, counting things in pandas is a pretty trivial task. All we need to do is call the [`count`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html#pandas.DataFrame.count) method of the data frame and we get a summary of the number of data points in each column:\n",
    "\n",
    "> **Note:** If our columns have missing data (the Iris data set doesn't), then `count` will return the number of non-missing (i.e. valid) data points. We'll see this in a bit more detail next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the `mean` method, `count` accepts a `level` argument, so we can tell pandas to count the number of non-missing data points each species for each species like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a trivial example because each of the species has an equal number of samples, but why don't we use a pie chart to visualise this data?\n",
    "\n",
    "> **Note:** In many cases, sample categories are not evenly distributed, so examining the proportion of samples in each category is a valuble habit to form.\n",
    "\n",
    "Creating pie charts with pandas works in a similar way to creating bar charts: we call `plot` on the data we want to visualise, passing `kind='pie'` instead of `kind='bar'` to specify the output chart type. There is one small difference though: pie charts cannot represent more than one column of data at a time, so we must tell pandas to make individual plots for each column by passing the optional argument `subplots=True`, as in the cell below:\n",
    "\n",
    "> **Note:** While pie charts are a good technique for visualising *proportions*, they are a poor technique for visualising almost anything else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count(level='species').plot(kind='pie', subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pie charts look a bit squashed, right? We can fix this by passing the optional argument `figsize=(width,length)`, which adjusts the size of the chart output. For instance, to set the figure size to 16x4, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count(level='species').plot(kind='pie', subplots=True, figsize=(16,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** Setting the figure size like this works for any call to pandas' `plot` method. Try adjusting the size of one the bar charts we made earlier for practice!\n",
    "\n",
    "The pie charts above now have enough space, but their legends are taking up valuable visual real estate. We can fix this by reorganising the plots from a 4x1 grid into a 2x2 grid using the optional `layout` argument. To do this, all we need to do is pass `layout=(2,2)` to the plot command (also setting `figsize=(12,12)` to compensate for the change in size), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.count(level=0).plot(kind='pie', subplots=True, figsize=(12,12), layout=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Histograms\n",
    "\n",
    "In lectures, we've seen how histograms can be used to visualise the distribution of the data in a sample. Again, using pandas, this is easily done using the `plot` method. The only difference this time is that we must set `kind='hist'`. For instance, to plot histograms for each column in the data frame, we can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plot data for just one species of Iris, then we need to index into the data frame first (like we did with the `describe` method earlier), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix['setosa'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like with pie charts, we can force pandas to create a plot for each variable type by specifying the options `subplots=True` and `layout=(2,2)` (the `figsize` option is also used to make sure the plots are big enough to see), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix['setosa'].plot(kind='hist', subplots=True, layout=(2,2), figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can increase the number of bins to get some finer detail about the distributions using the `bins` argument, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix['setosa'].plot(kind='hist', subplots=True, layout=(2,2), figsize=(12,6), bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try varying the number of bins to see the effect it has on the disributions. Remember, if the number of bins is too large, you'll start to get a \"broken comb\" look.\n",
    "\n",
    "#### Scatter plot matrices\n",
    "\n",
    "Creating histograms for a single species is informative, but we're missing out on the bigger picture. One of the most important aspects of exploratory data analysis is determining whether there are any relationships in your data and one of the best techniques for visualising this is the scatter plot matrix.\n",
    "\n",
    "Before we get to building a matrix for our data, let's consider the quantitative approach first: computing correlations for each pair of variables in our data set. With pandas, this is easy - all we need to do is call the [`corr`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html) method on our data frame, like in the cell below, and pandas computes the Pearson correlation coefficient for each pair of variables in our data set and presents the data as a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the data, petal length is highly positively correlated to sepal length.\n",
    "\n",
    "> **Note:** By definition, a data sample is always completely positively correlated to itself (i.e. $r_{xx} = 1$). This is why the diagonal entries in the table above are all equal to one.\n",
    "\n",
    "Next, let's consider the qualitative approach: in pandas, we can make a scatter plot from a data frame by passing it to pandas' [`scatter_matrix`](http://pandas.pydata.org/pandas-docs/stable/visualization.html#scatter-matrix-plot) function, like this:\n",
    "\n",
    "> **Note:** Unlike the other methods we've covered today, `scatter_matrix` is not an option we can pass to `plot`, i.e. we cannot call `df.plot(kind='scatter_matrix')`. Instead, we must always pass the data frame to the method as in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df, figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good, but the points in our scatter plot are a little small. We can change this by specifying the optional `s` argument (`s` stands for size), like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.scatter_matrix(df, figsize=(12, 12), s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much clearer! We can now easily spot correlations visually, e.g. petal width and petal length, which will help us form hypotheses about what the final outcome of our analysis might be. For example, in this case, we might conclude that species with larger petal widths have larger petal lengths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
